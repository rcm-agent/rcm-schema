# V8 Graph Workflows Guide

## Overview

V8 introduces a DAG (Directed Acyclic Graph) based workflow system, replacing linear task sequences with flexible, parallel-capable workflow graphs.

## Core Concepts

### 1. Workflow Nodes

Nodes represent discrete steps in a workflow:

```sql
CREATE TABLE workflow_node (
    node_id       BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    code          TEXT UNIQUE,
    description   TEXT,
    metadata      JSONB DEFAULT '{}'::jsonb,
    label_conf    NUMERIC(3,2),  -- Confidence in node labeling
    last_label_at TIMESTAMPTZ
);
```

Example nodes:
```sql
INSERT INTO workflow_node (code, description, metadata) VALUES
('login_portal', 'Login to payer portal', '{"portal_type": "payer"}'),
('search_patient', 'Search for patient', '{"search_fields": ["name", "dob", "member_id"]}'),
('verify_eligibility', 'Verify eligibility status', '{"output_fields": ["coverage", "copay"]}'),
('submit_auth', 'Submit authorization', '{"required_docs": ["clinical_notes", "diagnosis"]}');
```

### 2. Workflow Transitions

Edges define valid paths between nodes:

```sql
CREATE TABLE workflow_transition (
    from_node    BIGINT REFERENCES workflow_node(node_id),
    to_node      BIGINT REFERENCES workflow_node(node_id),
    action_label TEXT NOT NULL,
    freq         INTEGER DEFAULT 1,  -- Frequency/weight
    PRIMARY KEY (from_node, to_node, action_label)
);
```

Example transitions:
```sql
-- Linear flow
INSERT INTO workflow_transition (from_node, to_node, action_label, freq) VALUES
(1, 2, 'login_success', 150),    -- login → search
(2, 3, 'patient_found', 145),    -- search → verify
(3, 4, 'needs_auth', 50);        -- verify → submit

-- Parallel paths
INSERT INTO workflow_transition VALUES
(2, 3, 'check_eligibility', 100),
(2, 5, 'check_benefits', 100),   -- Can do both in parallel
(3, 6, 'merge_results', 90),
(5, 6, 'merge_results', 90);     -- Both converge to merge node

-- Error handling
INSERT INTO workflow_transition VALUES
(1, 1, 'login_retry', 5),        -- Self-loop for retry
(2, 7, 'patient_not_found', 10); -- Error path
```

### 3. User Workflows

Instances of workflow execution:

```sql
CREATE TABLE user_workflow (
    workflow_id   UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name          TEXT NOT NULL,
    description   TEXT,
    required_data JSONB DEFAULT '[]'::jsonb,
    created_at    TIMESTAMPTZ NOT NULL DEFAULT now()
);
```

## Workflow Execution

### Starting a Workflow

```python
async def start_workflow(
    session: AsyncSession,
    name: str,
    start_node: str,
    required_data: dict
) -> UUID:
    # Create workflow instance
    workflow = UserWorkflow(
        name=name,
        required_data=required_data
    )
    session.add(workflow)
    
    # Find start node
    start = await session.execute(
        select(WorkflowNode).where(WorkflowNode.code == start_node)
    )
    
    # Create initial trace
    trace = WorkflowTrace(
        org_id=org_context.org_id,
        workflow_id=workflow.workflow_id,
        action_type="workflow_start",
        action_detail={"node": start_node}
    )
    session.add(trace)
    
    await session.commit()
    return workflow.workflow_id
```

### Finding Next Steps

```python
async def get_next_nodes(
    session: AsyncSession,
    current_node_id: int
) -> List[WorkflowNode]:
    # Get all possible transitions
    transitions = await session.execute(
        select(WorkflowTransition, WorkflowNode)
        .join(WorkflowNode, WorkflowTransition.to_node == WorkflowNode.node_id)
        .where(WorkflowTransition.from_node == current_node_id)
        .order_by(WorkflowTransition.freq.desc())
    )
    
    return [node for _, node in transitions]
```

### Parallel Execution

```python
async def execute_parallel_nodes(
    workflow_id: UUID,
    nodes: List[WorkflowNode]
) -> List[WorkflowTrace]:
    # Create tasks for parallel execution
    tasks = []
    for node in nodes:
        task = asyncio.create_task(
            execute_node(workflow_id, node)
        )
        tasks.append(task)
    
    # Wait for all to complete
    results = await asyncio.gather(*tasks)
    return results
```

## Micro-States Integration

Each node execution generates micro-states:

```python
async def execute_node(
    workflow_id: UUID,
    node: WorkflowNode
) -> WorkflowTrace:
    # Execute browser action
    dom_snapshot, screenshot = await browser.execute(node.metadata)
    
    # Generate embedding
    text_emb = await embed_text(dom_snapshot)
    
    # Store micro-state
    micro_state = MicroState(
        workflow_id=workflow_id,
        node_id=node.node_id,
        dom_snapshot=dom_snapshot,
        action_json=node.metadata,
        text_emb=text_emb
    )
    session.add(micro_state)
    
    # Create trace
    trace = WorkflowTrace(
        workflow_id=workflow_id,
        action_type=node.code,
        success=True
    )
    session.add(trace)
    
    return trace
```

## Workflow Patterns

### 1. Sequential Flow
```
Login → Search → Verify → Submit
```

### 2. Parallel Split
```
        ┌→ Check Eligibility ─┐
Search ─┤                      ├→ Merge Results
        └→ Check Benefits ────┘
```

### 3. Conditional Branching
```
Verify ─┬→ [Approved] → Complete
        └→ [Needs Auth] → Submit → Appeal
```

### 4. Error Recovery
```
Login ─┬→ [Success] → Continue
       └→ [Failed] → Retry → [Max Retries] → Manual
```

## Learning & Optimization

### Transition Frequency Updates

```sql
-- Update frequency based on usage
UPDATE workflow_transition 
SET freq = freq + 1
WHERE from_node = :from AND to_node = :to AND action_label = :action;
```

### Node Confidence Updates

```sql
-- Update node labeling confidence
UPDATE workflow_node
SET label_conf = :new_confidence,
    last_label_at = now()
WHERE node_id = :node_id;
```

### Finding Optimal Paths

```sql
WITH RECURSIVE path_search AS (
    -- Start node
    SELECT 
        node_id,
        code,
        0 as depth,
        ARRAY[node_id] as path,
        0 as total_cost
    FROM workflow_node
    WHERE code = 'login_portal'
    
    UNION ALL
    
    -- Recursive step
    SELECT 
        wn.node_id,
        wn.code,
        ps.depth + 1,
        ps.path || wn.node_id,
        ps.total_cost + (100 - wt.freq) -- Lower freq = higher cost
    FROM path_search ps
    JOIN workflow_transition wt ON ps.node_id = wt.from_node
    JOIN workflow_node wn ON wt.to_node = wn.node_id
    WHERE wn.node_id != ALL(ps.path) -- Prevent cycles
    AND ps.depth < 10 -- Max depth
)
SELECT * FROM path_search
WHERE code = 'submit_complete'
ORDER BY total_cost
LIMIT 1;
```

## Best Practices

1. **Start Simple**: Begin with linear flows, add parallelism later
2. **Label Clearly**: Use descriptive node codes and action labels
3. **Track Frequency**: Let the system learn common paths
4. **Handle Errors**: Always include error transitions
5. **Limit Depth**: Prevent infinite loops with depth limits

## Migration from Linear Workflows

```sql
-- Convert task_type to workflow nodes
INSERT INTO workflow_node (code, description, metadata)
SELECT 
    domain || '_' || action as code,
    display_name as description,
    jsonb_build_object('legacy_task_type_id', task_type_id)
FROM task_type;

-- Create linear transitions
INSERT INTO workflow_transition (from_node, to_node, action_label)
SELECT 
    lag(node_id) OVER (ORDER BY created_at),
    node_id,
    'next_step'
FROM workflow_node
WHERE lag(node_id) OVER (ORDER BY created_at) IS NOT NULL;
```